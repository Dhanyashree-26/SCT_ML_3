import os
import numpy as np
import cv2
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import make_pipeline
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from PIL import Image

def load_images_and_labels(image_dir, image_size=(64, 64), max_images_per_class=500):
    images = []
    labels = []
    for label in ['dogs', 'cats']: 
        label_dir = os.path.join(image_dir, label)
        if not os.path.isdir(label_dir):
            print(f"Warning: Directory {label_dir} not found. Please check the path.")
            continue
        print(f"Loading images from: {label_dir}")
        for idx, img_name in enumerate(os.listdir(label_dir)):
            if idx >= max_images_per_class:
                break
            img_path = os.path.join(label_dir, img_name)
            try:
                img = cv2.imread(img_path)
                if img is None:
                    print(f"Warning: Could not read image {img_path}. Skipping.")
                    continue
                img = cv2.resize(img, image_size)
                img = img.flatten()  
                images.append(img)
                labels.append(label)
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")
    print(f"Loaded {len(images)} images from {image_dir}")
    return np.array(images), np.array(labels)

train_dir = r'C:\Users\dhanyashree\Downloads\archive (7)\train' 
test_dir = r'C:\Users\dhanyashree\Downloads\archive (7)\test'   

X_train, y_train = load_images_and_labels(train_dir, max_images_per_class=500)
X_test, y_test = load_images_and_labels(test_dir, max_images_per_class=250)

if X_train.size == 0 or y_train.size == 0:
    raise ValueError("No images found in the training dataset. Check the training dataset path and structure.")
if X_test.size == 0 or y_test.size == 0:
    raise ValueError("No images found in the testing dataset. Check the testing dataset path and structure.")

label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


pipeline = make_pipeline(StandardScaler(), PCA(n_components=30), svm.SVC())

param_grid = {
    'pca__n_components': [30, 40, 60],
    'svc__C': [0.1, 1, 10],
    'svc__gamma': [0.01, 0.1, 'scale'],
    'svc__kernel': ['rbf']
}

grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)
print("Performing grid search...")
grid_search.fit(X_train, y_train)
print("Best parameters found:", grid_search.best_params_)

svm_model = grid_search.best_estimator_

print("Evaluating the model...")
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy on test set: {accuracy * 100:.2f}%')

def classify_image(image_path):
    img = Image.open(image_path).convert('RGB')
    img = img.resize((64, 64)) 
    img = np.array(img)
    img = img.flatten()  
    img = np.expand_dims(img, axis=0) 
    prediction = svm_model.predict(img)
    return label_encoder.inverse_transform(prediction)[0]

# Example usage: Classify a new image
image_path = r'C:\Users\dhanyashree\OneDrive\Desktop\c.jpeg'  
result = classify_image(image_path)
print(f'The image is classified as: {result}')
